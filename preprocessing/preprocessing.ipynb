{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b8d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01fb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from urllib.parse import urlparse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String processing\n",
    "def extract_features(url):\n",
    "    parsed = urlparse(url)\n",
    "    features = {}\n",
    "    features[\"url_length\"] = len(url)\n",
    "    features[\"num_dots\"] = url.count(\".\")\n",
    "    features[\"num_hyphens\"] = url.count(\"-\")\n",
    "    features[\"num_at\"] = url.count(\"@\")\n",
    "    features[\"uses_https\"] = int(parsed.scheme == \"https\")\n",
    "    features[\"has_ip\"] = int(bool(re.search(r'\\d+\\.\\d+\\.\\d+\\.\\d+', parsed.netloc)))\n",
    "    features[\"num_subdomains\"] = len(parsed.netloc.split(\".\")) - 2  \n",
    "    features[\"path_length\"] = len(parsed.path)\n",
    "    return features\n",
    "\n",
    "# Áp dụng cho tất cả URL trong DataFrame\n",
    "features_df = data[\"url\"].apply(extract_features).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality and merge back into the original data\n",
    "# Áp dụng PCA để giảm số chiều\n",
    "pca = PCA(n_components=2)  # Chỉ lấy một thành phần\n",
    "reduced_features = pca.fit_transform(features_df)\n",
    "\n",
    "pca_df = pd.DataFrame(reduced_features, columns=[\"pca1\", \"pca2\"])\n",
    "\n",
    "# Dùng để làm cho chỉ số khớp nhau trước khi nối \n",
    "pca_df.reset_index(drop=True, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Nối vào data gốc\n",
    "data = pd.concat([data, pca_df], axis=1)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "\n",
    "# #known_exploited_vulnerabilities.csv\n",
    "# data = data.dropna()\n",
    "# data = data.drop([\"dateAdded\",\"cveID\", \"vulnerabilityName\", \"shortDescription\", \"dueDate\", \"notes\"], axis=1)\n",
    "# data =data.drop_duplicates()\n",
    "\n",
    "#malicious_phish.csv\n",
    "print(data[\"type\"].unique())  # Kiểm tra tất cả giá trị duy nhất trong cột 'type'\n",
    "data.replace(\"nan\", np.nan, inplace=True)\n",
    "data = data.dropna()\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "statusMap = {\"benign\": 0, \"phishing\": 1, \"defacement\": 1, \"malware\": 1}\n",
    "data[\"type\"] = data[\"type\"].map(statusMap)\n",
    "print(data[\"type\"].isna().any())\n",
    "\n",
    "y = data[\"type\"].values.ravel()\n",
    "\n",
    "x = pd.DataFrame(data, columns=[\"pca1\", \"pca2\"])\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# #csic_database.csv\n",
    "# data = data.dropna()\n",
    "# data = data.drop([\"Pragma\", \"Cache-Control\", \"Accept\", \"Accept-encoding\", \"Accept-charset\", \"language\", \"cookie\", \"content\", \"classification\"], axis=1)\n",
    "# data =data.drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
